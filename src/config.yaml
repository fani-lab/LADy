default:
  - _self_

cmd:
  - prep
  - llmargs

prep:
  doctype: snt  # 'rvw' for single review, but 'snt' for segmented subreviews
  langaug: ['', 'pes_Arab', 'zho_Hans', 'deu_Latn', 'arb_Arab', 'fra_Latn', 'spa_Latn']
  translator: nllb
  nllb: facebook/nllb-200-distilled-600M
  max_l: 1500
  device: ${oc.env:CUDA_VISIBLE_DEVICES, "cpu"} # Use CUDA if available, esle CPU
  batch: true

args: # required for 'prep' step
  data: 
    #./data/raw/twitter/acl-14-short-data/toy.raw
    ../data/raw/mams/test.xml
    #./data/raw/semeval/toy.2016SB5/ABSA16_Restaurants_Train_SB1_v2.xml
  
  output: 
    #./output/twitter-agg
    ../output/mams-agg
    #./output/semeval-agg
  
  naspects:
    25  # Default Value
  
  am:
    rnd # Default Value

llmargs:
  use_api: true
  api_key: lm-studio
  api_base: http://localhost:1234/v1
  model_name: deepseek-r1-distill-qwen-32b
  temperature: 0.5
  max_tokens: 1024
  output: ../output/AspectAdded/semeval-agg/aspectAdded.pkl


